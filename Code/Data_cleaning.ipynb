{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5140410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf0f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Earthquake Prediction\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b6da28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------+-----+---+-------+----+-----+----+----+-----+-------------+--------------------+--------------------+----------+---------------+----------+--------+------+--------+--------------+---------+\n",
      "|                time|latitude|longitude|depth|mag|magType| nst|  gap|dmin| rms|  net|           id|             updated|               place|      type|horizontalError|depthError|magError|magNst|  status|locationSource|magSource|\n",
      "+--------------------+--------+---------+-----+---+-------+----+-----+----+----+-----+-------------+--------------------+--------------------+----------+---------------+----------+--------+------+--------+--------------+---------+\n",
      "|2013-05-31T23:58:...|  43.304| -105.404|  0.0|3.1|     ml|10.0|141.5|null|1.89|rusms|rusms00005459|2022-06-09T21:13:...|50 km S of Wright...| explosion|           null|      null|    null|  null|reviewed|            us|       us|\n",
      "|2013-05-31T22:34:...|  51.127|  -178.08| 26.0|3.1|     ml|17.0|261.5|null|null|   us|   us2013qwdh|2023-07-18T16:47:...|130 km SW of Adak...|earthquake|           null|      null|    null|  null|reviewed|          aeic|     aeic|\n",
      "|2013-05-31T22:21:...|  21.648|  143.032|322.5|4.4|     mb|89.0| 40.0|null|0.55|   us|   usb000hb21|2014-11-07T01:50:...|Mariana Islands r...|earthquake|           null|       4.5|    null|  86.0|reviewed|            us|       us|\n",
      "|2013-05-31T20:17:...|  -10.28|   161.56| 58.8|4.7|     mb|48.0|105.0|null|0.92|   us|   us2013qwdc|2014-11-07T01:50:...|43 km WNW of Kira...|earthquake|           null|       6.3|    null|  40.0|reviewed|            us|       us|\n",
      "|2013-05-31T17:36:...|  -43.36|  172.945| 20.3|4.0|     ml|21.0|100.0|null|null|   us|   usb000hb8z|2014-11-07T01:50:...|South Island of N...|earthquake|           null|      null|    null|  null|reviewed|           wel|      wel|\n",
      "+--------------------+--------+---------+-----+---+-------+----+-----+----+----+-----+-------------+--------------------+--------------------+----------+---------------+----------+--------+------+--------+--------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", True).csv(\"combined_data.csv\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28f26f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(time='2013-05-31T23:58:13.560Z', latitude='43.304', longitude='-105.404', depth='0.0', mag='3.1', magType='ml', nst='10.0', gap='141.5', dmin=None, rms='1.89', net='rusms', id='rusms00005459', updated='2022-06-09T21:13:46.666Z', place='50 km S of Wright, Wyoming', type='explosion', horizontalError=None, depthError=None, magError=None, magNst=None, status='reviewed', locationSource='us', magSource='us')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df89456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'depth',\n",
       " 'mag',\n",
       " 'magType',\n",
       " 'nst',\n",
       " 'gap',\n",
       " 'dmin',\n",
       " 'rms',\n",
       " 'net',\n",
       " 'id',\n",
       " 'updated',\n",
       " 'place',\n",
       " 'type',\n",
       " 'horizontalError',\n",
       " 'depthError',\n",
       " 'magError',\n",
       " 'magNst',\n",
       " 'status',\n",
       " 'locationSource',\n",
       " 'magSource']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124efa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, to_timestamp, col\n",
    "\n",
    "# Directly convert string to timestamp and extract date\n",
    "df = df.withColumn(\"date\", to_date(to_timestamp(col(\"time\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08030bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'depth',\n",
       " 'mag',\n",
       " 'magType',\n",
       " 'nst',\n",
       " 'gap',\n",
       " 'dmin',\n",
       " 'rms',\n",
       " 'net',\n",
       " 'id',\n",
       " 'updated',\n",
       " 'place',\n",
       " 'type',\n",
       " 'horizontalError',\n",
       " 'depthError',\n",
       " 'magError',\n",
       " 'magNst',\n",
       " 'status',\n",
       " 'locationSource',\n",
       " 'magSource',\n",
       " 'date']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad2ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('time',\n",
    " 'magType',\n",
    " 'nst',\n",
    " 'gap',\n",
    " 'dmin',\n",
    " 'rms',\n",
    " 'net',\n",
    " 'id',\n",
    " 'updated',\n",
    " 'Type',\n",
    " 'horizontalError',\n",
    " 'depthError',\n",
    " 'magError',\n",
    " 'magNst',\n",
    " 'status',\n",
    " 'locationSource',\n",
    " 'magSource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164240bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude', 'longitude', 'depth', 'mag', 'place', 'date']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4a66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, trim\n",
    "\n",
    "# Split the string by comma and take the second part (after the comma)\n",
    "df = df.withColumn(\"place\", trim(split(col(\"place\"), \",\").getItem(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4440772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----+---+---------------+----------+\n",
      "|latitude|longitude|depth|mag|          place|      date|\n",
      "+--------+---------+-----+---+---------------+----------+\n",
      "|  43.304| -105.404|  0.0|3.1|        Wyoming|2013-06-01|\n",
      "|  51.127|  -178.08| 26.0|3.1|         Alaska|2013-06-01|\n",
      "|  21.648|  143.032|322.5|4.4|           null|2013-06-01|\n",
      "|  -10.28|   161.56| 58.8|4.7|Solomon Islands|2013-06-01|\n",
      "|  -43.36|  172.945| 20.3|4.0|           null|2013-05-31|\n",
      "+--------+---------+-----+---+---------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b44e9712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238992"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec50986d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|        place|          avg_mag|\n",
      "+-------------+-----------------+\n",
      "|         Utah|3.451642512077295|\n",
      "|       Hawaii|3.350071983852591|\n",
      "|       Russia|4.462530315278912|\n",
      "|     Anguilla|3.736242774566475|\n",
      "|Russia region|4.426767676767676|\n",
      "+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "# Average magnitude per place\n",
    "avg_mag_df = df.groupBy(\"place\").agg(avg(\"mag\").alias(\"avg_mag\"))\n",
    "avg_mag_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86ed6837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+\n",
      "|        place|          avg_mag|\n",
      "+-------------+-----------------+\n",
      "|         Utah|3.451642512077295|\n",
      "|       Hawaii|3.350071983852591|\n",
      "|       Russia|4.462530315278912|\n",
      "|     Anguilla|3.736242774566475|\n",
      "|Russia region|4.426767676767676|\n",
      "+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter places with avg_mag > 3\n",
    "dangerous_places_df = avg_mag_df.filter(col(\"avg_mag\") > 3)\n",
    "dangerous_places_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc8f1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average coordinates for each place\n",
    "coord_df = df.groupBy(\"place\").agg(\n",
    "    avg(\"latitude\").alias(\"latitude\"),\n",
    "    avg(\"longitude\").alias(\"longitude\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "037bdc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depth', 'mag', 'place', 'date']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('latitude','longitude')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da3d4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge coordinates back with original DataFrame (on 'place')\n",
    "df = df.join(coord_df, on=\"place\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "620eaa38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+----+----------+-------------------+-------------------+\n",
      "|             place| depth| mag|      date|           latitude|          longitude|\n",
      "+------------------+------+----+----------+-------------------+-------------------+\n",
      "|           Wyoming|   0.0| 3.1|2013-06-01|  43.73179712249905|-105.60074515264581|\n",
      "|            Alaska|  26.0| 3.1|2013-06-01|  55.57031222130659|-144.59539603275684|\n",
      "|   Solomon Islands|  58.8| 4.7|2013-06-01|-10.610102945544568| 162.91138339108923|\n",
      "|  Papua New Guinea|  35.0| 4.0|2013-05-31| -5.567790788234048|  150.3215314456188|\n",
      "|             Tonga| 101.9| 4.8|2013-05-31|-18.905669998471673| -174.8927523154518|\n",
      "|            Alaska|  13.1| 3.3|2013-05-31|  55.57031222130659|-144.59539603275684|\n",
      "|                CA|10.487|3.09|2013-05-31| 36.103720015592565|-118.86856682093632|\n",
      "|            Mexico| 108.5| 4.0|2013-05-31|  17.56200411031402| -98.26777818015127|\n",
      "|           Vanuatu|  10.0| 5.1|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|       Timor Leste| 158.2| 4.4|2013-05-31| -7.520029411764702| 127.36053548085901|\n",
      "|           Morocco|  10.4| 4.5|2013-05-31| 34.689088148148144| -4.556985185185186|\n",
      "|              Iran|  15.0| 4.0|2013-05-31| 30.577886284722226|  52.56704066840277|\n",
      "|           Vanuatu|  25.0| 4.4|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|           Vanuatu|  33.3| 4.6|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|Dominican Republic|  78.0| 4.2|2013-05-31|  18.72933538388173| -68.40764546971863|\n",
      "|         Indonesia|  76.9| 4.5|2013-05-31| -2.479362318840573| 119.99581367270119|\n",
      "|              Iran|  14.1| 4.6|2013-05-31| 30.577886284722226|  52.56704066840277|\n",
      "|       Afghanistan| 195.3| 4.3|2013-05-31|  36.37362978219696|  70.40958039772731|\n",
      "|           Vanuatu|  10.0| 4.9|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|         Indonesia|  77.8| 4.3|2013-05-31| -2.479362318840573| 119.99581367270119|\n",
      "+------------------+------+----+----------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e5bd3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- place: string (nullable = true)\n",
      " |-- depth: string (nullable = true)\n",
      " |-- mag: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "543f43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Cast columns to appropriate types\n",
    "df = df.withColumn(\"depth\", col(\"depth\").cast(DoubleType())) \\\n",
    "       .withColumn(\"mag\", col(\"mag\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0e17ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- place: string (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- mag: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb003bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+----+----------+-------------------+-------------------+\n",
      "|             place| depth| mag|      date|           latitude|          longitude|\n",
      "+------------------+------+----+----------+-------------------+-------------------+\n",
      "|           Wyoming|   0.0| 3.1|2013-06-01|  43.73179712249905|-105.60074515264581|\n",
      "|            Alaska|  26.0| 3.1|2013-06-01|  55.57031222130659|-144.59539603275684|\n",
      "|   Solomon Islands|  58.8| 4.7|2013-06-01|-10.610102945544568| 162.91138339108923|\n",
      "|  Papua New Guinea|  35.0| 4.0|2013-05-31| -5.567790788234048|  150.3215314456188|\n",
      "|             Tonga| 101.9| 4.8|2013-05-31|-18.905669998471673| -174.8927523154518|\n",
      "|            Alaska|  13.1| 3.3|2013-05-31|  55.57031222130659|-144.59539603275684|\n",
      "|                CA|10.487|3.09|2013-05-31| 36.103720015592565|-118.86856682093632|\n",
      "|            Mexico| 108.5| 4.0|2013-05-31|  17.56200411031402| -98.26777818015127|\n",
      "|           Vanuatu|  10.0| 5.1|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|       Timor Leste| 158.2| 4.4|2013-05-31| -7.520029411764702| 127.36053548085901|\n",
      "|           Morocco|  10.4| 4.5|2013-05-31| 34.689088148148144| -4.556985185185186|\n",
      "|              Iran|  15.0| 4.0|2013-05-31| 30.577886284722226|  52.56704066840277|\n",
      "|           Vanuatu|  25.0| 4.4|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|           Vanuatu|  33.3| 4.6|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|Dominican Republic|  78.0| 4.2|2013-05-31|  18.72933538388173| -68.40764546971863|\n",
      "|         Indonesia|  76.9| 4.5|2013-05-31| -2.479362318840573| 119.99581367270119|\n",
      "|              Iran|  14.1| 4.6|2013-05-31| 30.577886284722226|  52.56704066840277|\n",
      "|       Afghanistan| 195.3| 4.3|2013-05-31|  36.37362978219696|  70.40958039772731|\n",
      "|           Vanuatu|  10.0| 4.9|2013-05-31|-16.342389658335247| 167.95876039899116|\n",
      "|         Indonesia|  77.8| 4.3|2013-05-31| -2.479362318840573| 119.99581367270119|\n",
      "+------------------+------+----+----------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93cf37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.repartition(1).write.csv(\"cleaned_data\",header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cab314c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"schema.txt\", \"w\") as f:\n",
    "    f.write(df.schema.simpleString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9962991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198550"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
